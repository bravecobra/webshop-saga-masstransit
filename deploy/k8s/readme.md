# Deploy on kubernetes on Docker Desktop

## Prerequisites

Tested on:
Windows Docker Desktop :
![Version](./docker-version.png)

Make sure you're in the correct directory

```shell
cd deploy/k8s
```

### Getting insight

Make sure you can connect to your k8s cluster and/or have an IDE like [Lens](https://k8slens.dev/) to see visually what is going on.

To create a (optional) topology map of your cluster use weave's [scope](https://www.weave.works/oss/scope/).

```powershell
kubectl create namespace weave
kubectl create -f 'https://cloud.weave.works/launch/k8s/weavescope.yaml' --namespace=weave
kubectl port-forward service/weave-scope-app 4040:80 --namespace weave
```

## Deploying the infrastructure

Make sure that helm repo's are up to date.

```powershell
helm repo add hashicorp https://helm.releases.hashicorp.com
helm repo add jaegertracing https://jaegertracing.github.io/helm-charts
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo update
```

> Stable Charts may have moved. Look at the [different repo's](https://github.com/helm/charts/issues/21103)

Now we deploy the controlplane part being consul, vault and jaeger

### Consul

#### Running a Consul instance

```powershell
kubectl apply -f infrastructure/namespace.yaml

helm install -f infrastructure/consul-values.yaml consul hashicorp/consul --namespace=infrastructure

kubectl port-forward service/consul-consul-server 8500:8500 --namespace infrastructure
```

* Consul [values.yaml](https://github.com/hashicorp/consul-helm/blob/master/values.yaml)

#### Forward internal DNS Queries to Consul with CoreDNS

In order for the internal services to be able to use the Consul DNS, we need to update the CoreDNS configmap to add consul as a DNS server

Fetch the ip address of the Consul DNS

```powershell
kubectl get svc consul-consul-dns -o jsonpath='{.spec.clusterIP}' --namespace=infrastructure
```

Update the values of the consul dns service in `.\infrastructure\coredns.yaml`

> Important: `coredns.yaml` is the syntax for CoreDNS 1.7.0, matching the tested. You can also fetch the current configmap and append the consul part as described in the [Consul Docs](https://www.consul.io/docs/k8s/dns).

```powershell
kubectl apply -f .\infrastructure\coredns.yaml
```

Test it out by running a job

```powershell
kubectl apply -f .\infrastructure\test-dns-job.yaml --namespace=webshop
```

### Running a Vault instance

```powershell
helm install -f infrastructure/vault-values.yaml vault hashicorp/vault --namespace=infrastructure

kubectl port-forward service/vault-ui 8200:8200 --namespace infrastructure
```

* Vault [values.yml](https://github.com/hashicorp/vault-helm/blob/master/values.yaml)

We need to unseal the vault before we can use it.
Follow the UI to unseal by creating 5 keys, applying 3. Download the keys as json and apply 3 of the base64 keys.
Login (again) with the root token and create an admin policy with the content of `./infrastructure/vault-admin-policy.json`. Then enable the userpass under the auth methods and create a new user `webui` with a password and add the `admin` policy under `Generated Token's Policies`.

### Running a Jaeger instance for distributed tracing

```powershell
helm install -f ./infrastructure/jaeger-values.yaml jaeger jaegertracing/jaeger --namespace=infrastructure

kubectl port-forward service/jaeger-query 8080:80 --namespace infrastructure
```

* Jaeger [values.yml](https://github.com/jaegertracing/helm-charts/blob/master/charts/jaeger/values.yaml)

> Jaeger alternative: [all-in-one-memory](https://raw.githubusercontent.com/jaegertracing/jaeger-kubernetes/master/all-in-one/jaeger-all-in-one-template.yml)

### Consul Ingress

To avoid the proxy forward we can expose them through an ingress. The Consul Connect ingress limitations are

1. Only the service that Consul Connect knows about (the ones that have a sidecar injected) can be exposed this way.
1. No TCP services can be exposed by hostname
1. No Socket support

```powershell
kubectl apply -f ./infrastructure/ingress-gateway.yaml
```

## The application

Now we can deploy the app in parts. First let's setup the app's infrastructure. We already setup the namespace for it. If not use the command below.

```powershell
kubectl apply -f webshop/namespace.yaml
```

### Setup sql server

We use the helm chart to deploy SQL server [stable/mssql-linux](https://github.com/helm/charts/tree/master/stable/mssql-linux).

```bash
helm install -f webshop/sqlserverdb.yaml sqlserverdb stable/mssql-linux --namespace=webshop
# kubectl apply -f https://www.getambassador.io/yaml/consul/ambassador-consul-connector.yaml --namespace=webshop
```

* SQLServer [values.yaml](https://github.com/helm/charts/blob/master/stable/mssql-linux/values.yaml)

To gain access to sqlserverdb, we need the autogenerated password the helmchart created in a kubernetes secret called `sqlserverdb-mssql-linux-secret` in the `webshop` namespace.

```bash
printf $(kubectl get secret --namespace webshop sqlserverdb-mssql-linux-secret -o jsonpath="{.data.sapassword}" | base64 --decode);echo
```

#### CLI

You can test that SQL Server is available by the service port with the following set of command:

```bash
kubectl run mssqlcli --image=microsoft/mssql-tools -ti --restart=Never --rm=true -- /bin/bash
sqlcmd -S sqlserverdb-mssql-linux.webshop,1433 -U sa
Password: <Enter Password for SA>
```

<!-- NwFESRAjXr7XFUw00gKs -->
You should now have a prompt where we can execute SQL like:

```sql
select @@version;
```

#### SSMS

To connect from SSMS, first forward the port to the k8s service.

```bash
kubectl port-forward service/sqlserverdb-mssql-linux 1433:1433 --namespace webshop
```

> Be sure to use `127.0.0.1,1433` for the server instead of `localhost,1433`

### RabbitMQ

Installing is done by:

```powershell
helm install -f ./webshop/rabbitmq-values.yaml rabbitmq bitnami/rabbitmq --namespace webshop

kubectl port-forward --namespace webshop svc/rabbitmq 15672:15672
```

RabbitMQ [values.yaml](https://github.com/bitnami/charts/blob/master/bitnami/rabbitmq/values.yaml)

Credentials (in bash):

```bash
    echo "Username      : user"
    echo "Password      : $(kubectl get secret --namespace webshop rabbitmq -o jsonpath="{.data.rabbitmq-password}" | base64 --decode)"
    echo "ErLang Cookie : $(kubectl get secret --namespace webshop rabbitmq -o jsonpath="{.data.rabbitmq-erlang-cookie}" | base64 --decode)"
```

If you ever ran this before, deleting the release will not remove the Persistent Volume Claim. So starting it again will re-use it, thus using the old credentials as well. So make sure you delete the old PVC, before installing the new release.

To upgrade an existing helm release you need to pass the ERLANG_COOKIE like this:

```powershell
helm upgrade -f ./webshop/rabbitmq-values.yaml rabbitmq bitnami/rabbitmq --namespace webshop --set auth.erlangCookie="VALUE_OF_ERLANG_COOKIE"
```

### Catalog Service

```powershell
helm install -f ./webshop/catalog-values.yaml catalog ./webshop/charts/catalog --namespace=webshop

kubectl port-forward --namespace catalog svc/catalog 80:8081
```

### Vault configuration

Configure vault to create db users

```powershell
# Login to Vault
$global:VAULT_ADDR="http://127.0.0.1:8200"
vault login -address="$global:VAULT_ADDR" -method=userpass username=webui password=webui

# get the sql server password secret from K8S
$dbpass64=kubectl get secret --namespace webshop sqlserverdb-mssql-linux-secret -o jsonpath="{.data.sapassword}"
$dbpass=[System.Text.Encoding]::ASCII.GetString([System.Convert]::FromBase64String($dbpass64))

vault auth enable -address="$global:VAULT_ADDR" approle
## Use a static DB Credential -> with the sa:$dbpass
vault secrets enable -address="$global:VAULT_ADDR" -path='Catalog' -version=2 kv
vault kv put -address="$global:VAULT_ADDR" Catalog/static "password=$dbpass"

## Use a dynamic DB Credential -> created when "vault read -address="$global:VAULT_ADDR" CatalogDB/creds/Catalog-role"
vault secrets enable -address="$global:VAULT_ADDR" -path='CatalogDB' database
vault write -address="$global:VAULT_ADDR" CatalogDB/config/Catalog-database plugin_name=mssql-database-plugin connection_url='sqlserver://{{username}}:{{password}}@mssql-linux:1433' allowed_roles="Catalog-role" username="sa" password=$dbpass

vault write -address="$global:VAULT_ADDR" CatalogDB/roles/Catalog-role db_name=Catalog-database creation_statements="CREATE LOGIN [{{name}}] WITH PASSWORD = '{{password}}'; USE Catalog; CREATE USER [{{name}}] FOR LOGIN [{{name}}]; GRANT SELECT,UPDATE,INSERT,DELETE TO [{{name}}];" default_ttl="2m" max_ttl="5m"

vault policy write -address="$global:VAULT_ADDR" Catalog ./webshop/Catalog-role-policy.hcl

vault write -address="$global:VAULT_ADDR" auth/approle/role/Catalog-role role_id="Catalog-role" token_policies="Catalog" token_ttl=1h token_max_ttl=2h secret_id_num_uses=5

Write-Output "Catalog-role" > Catalog-role-id
vault write -f -address="$global:VAULT_ADDR" -field=secret_id auth/approle/role/Catalog-role/secret-id > Catalog-secret-id

# Get a dynamic credential
vault read -address="$global:VAULT_ADDR" CatalogDB/creds/Catalog-role

# Let's inject automatically through the sidecar
#Let vault talk to kubernetes
vault auth enable kubernetes -address="$global:VAULT_ADDR"

kubectl -n infrastructure create serviceaccount vault-auth

kubectl -n infrastructure apply --filename ./infrastructure/vault-auth-serviceaccount.yaml

# Set VAULT_SA_NAME to the service account you created earlier
$VAULT_SA_NAME=kubectl -n infrastructure get sa vault-auth -o jsonpath="{.secrets[*]['name']}"
# Set SA_JWT_TOKEN value to the service account JWT used to access the TokenReview API
$SA_JWT_TOKEN64=kubectl -n infrastructure get secret $VAULT_SA_NAME -o jsonpath="{.data.token}"
$SA_JWT_TOKEN=[System.Text.Encoding]::ASCII.GetString([System.Convert]::FromBase64String($SA_JWT_TOKEN64))
# Set SA_CA_CRT to the PEM encoded CA cert used to talk to Kubernetes API
$SA_CA_CRT64=kubectl -n infrastructure get secret $VAULT_SA_NAME -o jsonpath="{.data['ca\.crt']}"
$SA_CA_CRT=[System.Text.Encoding]::ASCII.GetString([System.Convert]::FromBase64String($SA_CA_CRT64))

# Look in your cloud provider console for this value
vault write auth/kubernetes/config  -address="$global:VAULT_ADDR" token_reviewer_jwt="$SA_JWT_TOKEN" kubernetes_host="https://$KUBERNETES_PORT_443_TCP_ADDR:443" kubernetes_ca_cert="$SA_CA_CRT"
```
